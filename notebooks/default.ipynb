{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24fb7419-0dbf-43d6-a734-25d0f3f224b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ollama:11434\n",
      "model: llama3.2:1b\n",
      "visual model: gemma3:4b\n",
      "embedding: nomic-embed-text:latest\n",
      "datapath /app/data\n",
      "no_proxy 127.0.0.0,localhsot,ollama,notebook\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OLLAMA_URL=os.getenv(\"OLLAMA_URL\")\n",
    "LLM_MODEL=os.getenv(\"LLM_MODEL\")\n",
    "LLM_MODEL_VISUAL=os.getenv(\"LLM_MODEL\")\n",
    "EMBEDDING_MODEL=os.getenv(\"EMBEDDING_MODEL\")\n",
    "DATAPATH=os.getenv(\"DATAPATH\")\n",
    "#OLLAMA_URL='http://localhost:11434'\n",
    "#LLM_MODEL=\"llama3.2:3b\" # max retires\n",
    "#LLM_MODEL=\"gemma3:4b\" # no tool support\n",
    "LLM_MODEL_VISUAL=\"gemma3:4b\"\n",
    "LLM_MODEL=\"llama3.2:1b\"\n",
    "DATAPATH=\"/app/data\"\n",
    "#LLM_MODEL=\"llava:7b\"\n",
    "#LLM_MODEL=\"codellama:7b\"\n",
    "#LLM_MODEL=\"qwen2.5-coder:1.5b\" # no tool support\n",
    "#LLM_MODEL=\"deepseek-r1:1.5b\" # does not support tools\n",
    "#os.setenv(\"no_proxy=localhost,127.0.0.1,*.my-it-solutions.net,ollama\")\n",
    "\n",
    "print(OLLAMA_URL)\n",
    "print(f\"model: {LLM_MODEL}\")\n",
    "print(f\"visual model: {LLM_MODEL_VISUAL}\")\n",
    "print(f\"embedding: {EMBEDDING_MODEL}\")\n",
    "print(f\"datapath {DATAPATH}\")\n",
    "print(f\"no_proxy {os.getenv('no_proxy')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40791bb1-6938-4a26-9265-c67379d6e9a1",
   "metadata": {},
   "source": [
    "Test connection to ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c54e76c-e63d-485f-a9d1-9ea9340f620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "response = requests.get(OLLAMA_URL,timeout=3)\n",
    "if response.status_code == requests.codes.ok:\n",
    "    print(response)\n",
    "else:\n",
    "    print(response)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745ca59-a6ee-4b16-bb75-3eb1a84c746f",
   "metadata": {},
   "source": [
    "Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "154bcc6a-e579-4df6-a16a-12462812569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=LLM_MODEL, request_timeout=120.0, base_url=OLLAMA_URL, temperature=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ce0e5e0-b2b3-4f0c-bd2a-0db511420163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.13/site-packages/pydantic/_internal/_core_utils.py:448: RuntimeWarning: coroutine 'Agent.run' was never awaited\n",
      "  def collect_refs(s: core_schema.CoreSchema, recurse: Recurse) -> core_schema.CoreSchema:\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[f\"{DATAPATH}/testdata.txt\",f\"{DATAPATH}/additionalinfo.txt\"]\n",
    ").load_data()\n",
    "print(\"loaded\")\n",
    "\n",
    "Settings.embed_model = OllamaEmbedding(model_name=EMBEDDING_MODEL, base_url=OLLAMA_URL,embed_batch_size=100)\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=30)\n",
    "# ollama\n",
    "Settings.llm = llm\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "documents,\n",
    "#embed_model=ollama_embedding,\n",
    ")\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1235f-5d7d-4a7d-aa28-208a5c750fc1",
   "metadata": {},
   "source": [
    "Demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4723fe57-a7aa-4429-a2fc-6c83e56be0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{ \"From\": \"Marco.Polo@wtc.com<Marco Polo>\", \"To\": \"Boris@arm.ru<Boris Invanovic>\", \"Subject\": \"Lieferung\", \n",
    "            \"Content\": \"Eine neue Lieferung steht bereit. Wir senden sie morge mit dem Flug TK9518 nach BEG\"}\n",
    "            ,{ \"From\": \"Boris@arm.ru<Boris Invanovic>\", \"To\": \"Chef51@mega.de\", \"Subject\": \"Info\", \n",
    "            \"Content\": \"Morgen können die neuen Bananen in BEG abgeholt werden. Grüsse Bo\"} #nick name Bo\n",
    "            ,{ \"From\": \"Boris@arm.ru<Boris Invanovic>\", \"To\": \"agent51@bunny.com\", \"Subject\": \"FW: Info\", \n",
    "            \"Content\": \"FYI\\n >>Morgen können die neuen Bananen in BEG abgeholt werden. Grüsse Bo\"} #nick name Bo\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca1f13-3824-4b0c-a513-a92ba7480766",
   "metadata": {},
   "source": [
    "Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c78c7ba-65cd-406e-92a7-c0465f5825ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Person entity.\"\"\"\n",
    "    name: str = Field(\n",
    "        ..., description=\"The name of a person\"\n",
    "    )\n",
    "    nickname: str = Field(\n",
    "        ..., description=\"The nickname of a person\"\n",
    "    )\n",
    "    email: str = Field(\n",
    "        ..., description=\"The email address of a person\"\n",
    "    )    \n",
    "\n",
    "class PersonList(BaseModel):\n",
    "    persons: List[Person]\n",
    "    \n",
    "\n",
    "def add_person_list(new_persons: PersonList, existing_list: Optional[PersonList] = None) -> PersonList:\n",
    "    \"\"\"\n",
    "    Add a person list to an empty or existing array of persons.\n",
    "    \n",
    "    Args:\n",
    "        new_persons: A PersonList object containing persons to be added\n",
    "        existing_list: An optional existing PersonList object to add to\n",
    "    \n",
    "    Returns:\n",
    "        A new PersonList containing the merged list of persons\n",
    "    \"\"\"\n",
    "    if existing_list is None:\n",
    "        return new_persons\n",
    "    \n",
    "    # Create a new list with all persons from both lists\n",
    "    merged_persons = PersonList(persons=existing_list.persons + new_persons.persons)\n",
    "    return merged_persons   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1ac488f-208b-40cf-a697-ddebc89c735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persons=[Person(name='John', nickname='Johnny', email='john@example.com'), Person(name='Jane', nickname='Janie', email='jane@example.com'), Person(name='Boris', nickname='Invanovic', email='agent51@bunny.com')]\n",
      "name='John Doe' nickname='Johnny' email='john@example.com'\n",
      "name='Bob Johnson' nickname='Bobby' email='bob@example.com'\n"
     ]
    }
   ],
   "source": [
    "# Knowledge base\n",
    "import json\n",
    "knowledge_person = []\n",
    "knowledge_person_plain = []\n",
    "\n",
    "#add_person_list(PersonList(Person=[{\"name\":\"Mario\",\"nickname\":\"MarioBo\",\"email\":\"ma@acme.com\"}]).Person,knowledge_person)\n",
    "\n",
    "people = PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"},\n",
    "    {\"name\": \"Boris\", \"nickname\": \"Invanovic\", \"email\": \"agent51@bunny.com\"},\n",
    "])\n",
    "print(people)\n",
    "                    \n",
    "person = Person(\n",
    "    name=\"John Doe\",\n",
    "    nickname=\"Johnny\",\n",
    "    email=\"john@example.com\"\n",
    ")\n",
    "print(person)\n",
    "json_data = '{\"name\": \"Bob Johnson\", \"nickname\": \"Bobby\", \"email\": \"bob@example.com\"}'\n",
    "data_dict = json.loads(json_data)\n",
    "person = Person.model_validate(data_dict)\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c242d2c-9111-4b43-a2de-ddaf310cddf8",
   "metadata": {},
   "source": [
    "Save new entities to memmory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "793d9a06-82c1-4076-b7dc-5ea577f26bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: {'From': 'Marco.Polo@wtc.com<Marco Polo>', 'To': 'Boris@arm.ru<Boris Invanovic>', 'Subject': 'Lieferung', 'Content': 'Eine neue Lieferung steht bereit. Wir senden sie morge mit dem Flug TK9518 nach BEG'}\n",
      "json\n",
      "Edit\n",
      "PersonList(persons=[\n",
      "    {\"name\": \"Marco Polo\", \"nickname\": \"\", \"email\": \"Marco.Polo@wtc.com\"},\n",
      "    {\"name\": \"Boris Invanovic\", \"nickname\": \"Boris\", \"email\": \"Boris@arm.ru\"}\n",
      "])\n",
      "json\n",
      "Edit\n",
      "PersonList(persons=[\n",
      "    {\"name\": \"Marco Polo\", \"nickname\": \"\", \"email\": \"Marco.Polo@wtc.com\"},\n",
      "    {\"name\": \"Boris Invanovic\", \"nickname\": \"Boris\", \"email\": \"Boris@arm.ru\"}\n",
      "])\n",
      "***\n",
      "query: {'From': 'Boris@arm.ru<Boris Invanovic>', 'To': 'Chef51@mega.de', 'Subject': 'Info', 'Content': 'Morgen können die neuen Bananen in BEG abgeholt werden. Grüsse Bo'}\n",
      "json\n",
      "Copy\n",
      "Edit\n",
      "PersonList(persons=[\n",
      "    {\"name\": \"Boris\", \"nickname\": \"\", \"email\": \"Boris@arm.ru\"},\n",
      "    {\"name\": \"Ivan\", \"nickname\": \"Petyr\", \"email\": \"\"}\n",
      "])\n",
      "json\n",
      "Copy\n",
      "Edit\n",
      "PersonList(persons=[\n",
      "    {\"name\": \"Boris\", \"nickname\": \"\", \"email\": \"Boris@arm.ru\"},\n",
      "    {\"name\": \"Ivan\", \"nickname\": \"Petyr\", \"email\": \"\"}\n",
      "])\n",
      "***\n",
      "query: {'From': 'Boris@arm.ru<Boris Invanovic>', 'To': 'agent51@bunny.com', 'Subject': 'FW: Info', 'Content': 'FYI\\n >>Morgen können die neuen Bananen in BEG abgeholt werden. Grüsse Bo'}\n",
      "json\n",
      "Edit\n",
      "PersonList(persons=[{\"name\": \"Boris\", \"nickname\": \"\", \"email\": \"Boris@arm.ru\"}, {\"name\": \"John\", \"nickname\": \"\", \"email\": \"john@example.com\"}])\n",
      "json\n",
      "Edit\n",
      "PersonList(persons=[{\"name\": \"Boris\", \"nickname\": \"\", \"email\": \"Boris@arm.ru\"}, {\"name\": \"John\", \"nickname\": \"\", \"email\": \"john@example.com\"}])\n",
      "***\n",
      "------------------\n",
      "['json\\nEdit\\nPersonList(persons=[\\n    {\"name\": \"Marco Polo\", \"nickname\": \"\", \"email\": \"Marco.Polo@wtc.com\"},\\n    {\"name\": \"Boris Invanovic\", \"nickname\": \"Boris\", \"email\": \"Boris@arm.ru\"}\\n])', 'json\\nCopy\\nEdit\\nPersonList(persons=[\\n    {\"name\": \"Boris\", \"nickname\": \"\", \"email\": \"Boris@arm.ru\"},\\n    {\"name\": \"Ivan\", \"nickname\": \"Petyr\", \"email\": \"\"}\\n])', 'json\\nEdit\\nPersonList(persons=[{\"name\": \"Boris\", \"nickname\": \"\", \"email\": \"Boris@arm.ru\"}, {\"name\": \"John\", \"nickname\": \"\", \"email\": \"john@example.com\"}])']\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.program.openai import OpenAIPydanticProgram\n",
    "#from llama_index.core.extractors import PydanticProgramExtractor\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "EXTRACT_TEMPLATE_STR = \"\"\"\\\n",
    "Here is the content of the section:\n",
    "----------------\n",
    "{context_str}\n",
    "----------------\n",
    "Given the contextual information, extract out all person object.\n",
    "A Person entity consists of: name, email.\n",
    "Only use the context information. Do not assume any other facts.\n",
    "Your output MUST follow this json EXACT format with EXACT field names:\\n\\n\n",
    "[{\"Persons:[{\"name\":\"Person Name\"},{\"email\":[Email address],\"nickname\":{Nickname}}}]}  ]\n",
    "\\\n",
    "\"\"\"\n",
    "\n",
    "EXTRACT_TEMPLATE_STR1 = \"\"\"\\\n",
    "Given the contextual information, extract a list of persons.\n",
    "If no persons are found return an emtpy list.\n",
    "Only use the context information. Do not assume any other facts.\n",
    "Your output MUST follow this json EXACT format with EXACT field names:\\n\\n\n",
    "PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"},\n",
    "])\n",
    "The output MUST be always a JSON Array.\n",
    "Only respond in the correct format, do not include additional properties in the JSON.\\n\n",
    "\"\"\"\n",
    "EXTRACT_TEMPLATE_STR2 = \"\"\"\\\n",
    "your are a assistand to extract informaiton. If needed you use tools.\n",
    "From the provided context, extract a list of persons mentioned in the text.\n",
    "\n",
    "Each person MUST include:\n",
    "\"name\": Full name of the person.\n",
    "\"nickname\": Nickname if mentioned, otherwise use an empty string \"\".\n",
    "\"email\": Email address if mentioned, otherwise use an empty string \"\".\n",
    "Constraints:\n",
    "\n",
    "Do NOT assume or invent any information not explicitly present in the context.\n",
    "If no persons are found, return an empty list: PersonList(persons=[]).\n",
    "Always respond with ONLY valid JSON following this EXACT structure (no extra text, no explanations):\n",
    "json\n",
    "Copy\n",
    "Edit\n",
    "PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"}\n",
    "])\n",
    "All fields MUST be present for each person, even if empty.\n",
    "The output MUST always be a valid JSON array inside PersonList, even when empty.\n",
    "Context to analyze:\n",
    "\"\"\"\n",
    "\n",
    "# extract only entities\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "ollama_model = OpenAIModel(model_name=LLM_MODEL, base_url=f\"{OLLAMA_URL}/v1\")\n",
    "                     \n",
    "#agent = Agent(model=ollama_model, result_type=str,system_prompt=EXTRACT_TEMPLATE_STR,retries=3)\n",
    "# deps_tpye is the input \n",
    "#agent = Agent(model=ollama_model,result_type=PersonList,deps_type=str,system_prompt=EXTRACT_TEMPLATE_STR2,retries=4)\n",
    "agent = Agent(model=ollama_model,result_type=str,deps_type=str,system_prompt=EXTRACT_TEMPLATE_STR2,retries=1)\n",
    "#TODO\n",
    "\n",
    "#import json\n",
    "#PersonList_schema = PersonList.model_json_schema()  # (1)!\n",
    "#print(json.dumps(PersonList_schema, indent=2))  # (2)!\n",
    "#print(json.dump())\n",
    "knowledge_person_plain = []\n",
    "for message in messages:\n",
    "    print(f\"query: {message}\")\n",
    "    entity_result = agent.run_sync(f\"{message}\")\n",
    "    print(entity_result.data) \n",
    "    #print(len(entity_result.data))\n",
    "    if isinstance(entity_result, PersonList):\n",
    "        add_person_list(knowledge_person.data)\n",
    "    if len(entity_result.data) > 2:        \n",
    "        knowledge_person_plain.append(entity_result.data)\n",
    "        print(entity_result.data)\n",
    "    print(\"***\")\n",
    "\n",
    "print(\"------------------\")\n",
    "print(knowledge_person_plain)\n",
    "#print(entity_result.data)\n",
    "#print(entity_result.usage())\n",
    "#memory.save(org_result.data)\n",
    "\n",
    "#print(entity_result.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e9cb1-cff2-446b-9328-d09e362d7510",
   "metadata": {},
   "source": [
    "Relation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b433a-ec9f-4d5d-862a-32d8b560beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation talk / known\n",
    "\n",
    "RELATE_TEMPLATE_STR = f\"\"\"\\\n",
    "Task:\n",
    "From the provided data, extract a graph of persons and their relationships.\n",
    "\n",
    "Graph structure:\n",
    "\n",
    "Nodes: Each person identified in the \"Entities to analyze\".\n",
    "Edges: Represent relationships between persons based on message content.\n",
    "Types of relations (edges):\n",
    "\n",
    "\"talk\": Two persons talk directly to each other.\n",
    "\"known\": The content indicates that one person knows another (e.g., mentions them as a known contact, friend, colleague).\n",
    "Constraints and Output Rules:\n",
    "\n",
    "ONLY use persons listed under \"Entities to analyze\" for nodes. Do not invent persons.\n",
    "If no relations are found, return an empty \"edges\" list.\n",
    "Always return a valid JSON object matching EXACTLY the structure shown in the example.\n",
    "DO NOT add any explanatory text or comments. Only output the JSON.\n",
    "All node IDs must match person names exactly as listed in \"Entities to analyze\" (case sensitive).\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"graph\": {{\n",
    "    \"nodes\": {{\n",
    "      \"Person1\": {{\"name\": \"John\"}},\n",
    "      \"Person2\": {{\"name\": \"Alice\"}}\n",
    "    }},\n",
    "    \"edges\": [\n",
    "      {{\n",
    "        \"source\": \"Person1\",\n",
    "        \"target\": \"Person2\",\n",
    "        \"relation\": \"talk\"\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Important:\n",
    "\n",
    "Use exact names from \"Entities to analyze\" as node IDs.\n",
    "Always include all persons as nodes, even if they have no edges.\n",
    "Follow exact JSON field names and structure as shown.\n",
    "\n",
    "\n",
    "Data to analyze:\n",
    "\"\"\"\n",
    "\n",
    "rel_agent = Agent(model=ollama_model,result_type=str,deps_type=str,system_prompt=RELATE_TEMPLATE_STR,retries=1)\n",
    "knowledge_person_plain\n",
    "\n",
    "relation_result = rel_agent.run_sync(f\"\"\"{messages} entities: {knowledge_person_plain}\"\"\")\n",
    "\n",
    "try:    \n",
    "    print(json.dumps(json.loads(relation_result.data), indent=4))\n",
    "except Exception as X:\n",
    "    print(f\"error {X}, print unformated\")\n",
    "    print(relation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24796ff4-0373-464e-825c-ee751b20bc9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relation_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m graph_data = json.loads(\u001b[43mrelation_result\u001b[49m.data)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Your JSON data (stored in a variable directly for this example)\u001b[39;00m\n\u001b[32m      7\u001b[39m xjson_data = \u001b[33m'''\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m{\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33m}\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[33m'''\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'relation_result' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph_data = json.loads(relation_result.data)\n",
    "# Your JSON data (stored in a variable directly for this example)\n",
    "xjson_data = '''\n",
    "{\n",
    "    \"graph\": {\n",
    "        \"nodes\": {\n",
    "            \"Marco Polo\": {\n",
    "                \"name\": \"Marco Polo\"\n",
    "            },\n",
    "            \"Boris Invanovic\": {\n",
    "                \"name\": \"Boris Invanovic\"\n",
    "            },\n",
    "            \"Bo\": {\n",
    "                \"name\": \"Boris Invanovic\"\n",
    "            }\n",
    "        },\n",
    "        \"edges\": [\n",
    "            {\n",
    "                \"source\": \"Marco Polo\",\n",
    "                \"target\": \"Boris Invanovic\",\n",
    "                \"relation\": \"talk\"\n",
    "            },\n",
    "            {\n",
    "                \"source\": \"Boris Invanovic\",\n",
    "                \"target\": \"Bo\",\n",
    "                \"relation\": \"talk\"\n",
    "            },\n",
    "            {\n",
    "                \"source\": \"Boris Invanovic\",\n",
    "                \"target\": \"Chef51@mega.de\",\n",
    "                \"relation\": \"known\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse JSON data\n",
    "graph_data = json.loads(json_data)\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes - here's the fix: use the node_id directly as both the node and its label\n",
    "for node_id, node_info in graph_data[\"graph\"][\"nodes\"].items():\n",
    "    G.add_node(node_id)  # The node_id is the key like \"Marco Polo\"\n",
    "\n",
    "# Also add any nodes that appear in edges but not in nodes section\n",
    "all_nodes = set(graph_data[\"graph\"][\"nodes\"].keys())\n",
    "for edge in graph_data[\"graph\"][\"edges\"]:\n",
    "    if edge[\"source\"] not in all_nodes:\n",
    "        G.add_node(edge[\"source\"])\n",
    "    if edge[\"target\"] not in all_nodes:\n",
    "        G.add_node(edge[\"target\"])\n",
    "\n",
    "# Add edges with relation as attribute\n",
    "for edge in graph_data[\"graph\"][\"edges\"]:\n",
    "    G.add_edge(edge[\"source\"], edge[\"target\"], relation=edge[\"relation\"])\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G, seed=42)  # seed for reproducibility\n",
    "\n",
    "# Draw nodes and labels (directly use node IDs as labels)\n",
    "nx.draw_networkx_nodes(G, pos, node_color='skyblue', node_size=2000)\n",
    "nx.draw_networkx_labels(G, pos, font_size=12)  # No need for a labels dict\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, width=2, edge_color='gray')\n",
    "\n",
    "# Draw edge labels (relation type)\n",
    "edge_labels = nx.get_edge_attributes(G, 'relation')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red', font_size=10)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Person Relation Graph', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdde2824-ff36-4245-891d-73825b3a9208",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic_ai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunContext\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;129m@agent\u001b[39m.system_prompt\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_the_date\u001b[39m() -> \u001b[38;5;28mstr\u001b[39m:  \n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe date is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate.today()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m result = agent.run_sync(\u001b[33m'\u001b[39m\u001b[33mWhat is the date?\u001b[39m\u001b[33m'\u001b[39m, deps=\u001b[33m'\u001b[39m\u001b[33mFrank\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from pydantic_ai import RunContext\n",
    "\n",
    "@agent.system_prompt\n",
    "def add_the_date() -> str:  \n",
    "    return f'The date is {date.today()}.'\n",
    "\n",
    "result = agent.run_sync('What is the date?', deps='Frank')\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2df31d-f665-479f-bbc9-895ef993f42a",
   "metadata": {},
   "source": [
    "Extract data from image (only works with a model supporting images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9d5dd3-9663-4a8a-a551-b61797a29b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image loaded: data:image/jpeg;base64,/9j/4gx...\n",
      "```json\n",
      "{\n",
      " \"persons\": [\n",
      "   {\n",
      "     \"name\": \"МІКОЛАЙ\",\n",
      "     \"email\": \"\",\n",
      "     \"birthdate\": \"12 12 1989\",\n",
      "     \"nationality\": \"УКРАЇНА/UKR\"\n",
      "   }\n",
      " ]\n",
      "}\n",
      "```\n",
      "[]\n",
      "new test\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "EXTRACT_IMG_TEMPLATE_STR = \"\"\"\\\n",
    "Extract all possible information from the image.\n",
    "\n",
    "{ctx.deps}\n",
    "\n",
    "Add for any non latin text a translation to the latin alphabet in brackets.\n",
    "\n",
    "A Person entity consists of: name, email, birthdate, nationality.\n",
    "Only use the context information. Do not assume any other facts.\n",
    "If it's the  passport or id card the natianlity might be the same as the issuer country.\n",
    "Your output MUST follow this JSON EXACT format with EXACT field names:\n",
    "{\n",
    "  \"persons\": [\n",
    "    {\n",
    "      \"name\": \"[Person Name]\",    \n",
    "      \"email\": \"[Email address]\",\n",
    "      \"birthdate\": \"[birthdate]\",\n",
    "      \"nationality\": \"[nationality]\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "# Create the agent instance\n",
    "#agentImage = Agent(template=EXTRACT_IMG_TEMPLATE_STR)  # Define the agent\n",
    "# extract only entities\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "ollama_image_model = OpenAIModel(model_name=LLM_MODEL_VISUAL, base_url=f\"{OLLAMA_URL}/v1\",api_key=\"not-needed\")\n",
    "agentImage = Agent(model=ollama_image_model,result_type=str,deps_type=str,system_prompt=EXTRACT_IMG_TEMPLATE_STR,retries=1)\n",
    "\n",
    "# Open the image file in binary mode\n",
    "def load_img(path):\n",
    "    with open(path, 'rb') as img_file:\n",
    "        encoded_string = base64.b64encode(img_file.read())    \n",
    "    return f'data:image/jpeg;base64,{encoded_string.decode(\"utf-8\")}'\n",
    "\n",
    "    \n",
    "#image_data = load_img(f'{DATAPATH}/img/DO_UKR_AV.jpg')\n",
    "image_data = load_img('/app/data/img/DO_UKR_AV.jpg')\n",
    "\n",
    "print(f\"image loaded: {image_data[:30]}...\") \n",
    "\n",
    "from pydantic_ai import Agent, BinaryContent ,ImageUrl, RunContext\n",
    "message_history=[]\n",
    "\n",
    "result = agentImage.run_sync(\n",
    "    [\n",
    "        'Extrahiere die Informationen.',\n",
    "        ImageUrl(url=image_data),\n",
    "        \n",
    "    ]\n",
    "    ,message_history=[]\n",
    ")\n",
    "print(result.data)\n",
    "#message_history = result.new_messages()\n",
    "print(message_history)\n",
    "print(\"new test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b568bf-c3eb-47f8-828d-94477dcc4bb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunContext' object has no attribute 'operator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m deps = ImageExtarctorHelper(operator=\u001b[33m\"\u001b[39m\u001b[33mBob\u001b[39m\u001b[33m\"\u001b[39m, image_url=ImageUrl(url=image_data))\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#BinaryContent(data=image_response.content, media_type='image/png') )\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m result = \u001b[43magentImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWhat my name?\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m#usage_limits=UsageLimits(response_tokens_limit=100),\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:558\u001b[39m, in \u001b[36mAgent.run_sync\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m infer_name \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/tasks.py:306\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    304\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    309\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:316\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    307\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    308\u001b[39m     result_type=result_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     usage=usage,\n\u001b[32m    315\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (final_result := agent_run.result) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mThe graph run did not finish properly\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:1366\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1364\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, ResultDataT] | End[FinalResult[ResultDataT]]:\n\u001b[32m   1365\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1366\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(next_node):\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:782\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    781\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:760\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persistence.record_run(node_snapshot_id):\n\u001b[32m    759\u001b[39m         ctx = GraphRunContext(\u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.deps)\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m         \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    763\u001b[39m     \u001b[38;5;28mself\u001b[39m._snapshot_id = \u001b[38;5;28mself\u001b[39m._next_node.get_snapshot_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:136\u001b[39m, in \u001b[36mUserPromptNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: GraphRunContext[GraphAgentState, GraphAgentDeps[DepsT, NodeRunEndT]]\n\u001b[32m    135\u001b[39m ) -> ModelRequestNode[DepsT, NodeRunEndT]:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ModelRequestNode[DepsT, NodeRunEndT](request=\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_first_message(ctx))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:142\u001b[39m, in \u001b[36mUserPromptNode._get_first_message\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_first_message\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: GraphRunContext[GraphAgentState, GraphAgentDeps[DepsT, NodeRunEndT]]\n\u001b[32m    140\u001b[39m ) -> _messages.ModelRequest:\n\u001b[32m    141\u001b[39m     run_context = build_run_context(ctx)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     history, next_message = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_messages(\u001b[38;5;28mself\u001b[39m.user_prompt, ctx.state.message_history, run_context)\n\u001b[32m    143\u001b[39m     ctx.state.message_history = history\n\u001b[32m    144\u001b[39m     run_context.messages = history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:176\u001b[39m, in \u001b[36mUserPromptNode._prepare_messages\u001b[39m\u001b[34m(self, user_prompt, message_history, run_context)\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m messages, _messages.ModelRequest([_messages.UserPromptPart(user_prompt)])\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     parts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sys_parts(run_context)\n\u001b[32m    177\u001b[39m     parts.append(_messages.UserPromptPart(user_prompt))\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m messages, _messages.ModelRequest(parts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:201\u001b[39m, in \u001b[36mUserPromptNode._sys_parts\u001b[39m\u001b[34m(self, run_context)\u001b[39m\n\u001b[32m    199\u001b[39m messages: \u001b[38;5;28mlist\u001b[39m[_messages.ModelRequestPart] = [_messages.SystemPromptPart(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.system_prompts]\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sys_prompt_runner \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.system_prompt_functions:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     prompt = \u001b[38;5;28;01mawait\u001b[39;00m sys_prompt_runner.run(run_context)\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sys_prompt_runner.dynamic:\n\u001b[32m    203\u001b[39m         messages.append(_messages.SystemPromptPart(prompt, dynamic_ref=sys_prompt_runner.function.\u001b[34m__qualname__\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_system_prompt.py:34\u001b[39m, in \u001b[36mSystemPromptRunner.run\u001b[39m\u001b[34m(self, run_context)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     33\u001b[39m     function = cast(Callable[[Any], \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mself\u001b[39m.function)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _utils.run_in_executor(function, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_utils.py:30\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, partial(func, *args, **kwargs))\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/futures.py:286\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36madd_the_users_name\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;129m@agentImage\u001b[39m.system_prompt  \n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_the_users_name\u001b[39m(ctx: RunContext[ImageExtarctorHelper]) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m#print(f\"the operator name is {ctx.deps} The image is {ctx.deps}.\")\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(ctx)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe operator name is The image is Margot  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunContext' object has no attribute 'operator'"
     ]
    }
   ],
   "source": [
    "from pydantic.dataclasses import dataclass\n",
    "\n",
    "image_data = load_img('/app/data/img/DO_UKR_AV.jpg')\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ImageExtarctorHelper:\n",
    "    operator: str\n",
    "    image_url: ImageUrl\n",
    "\n",
    "@agentImage.system_prompt  \n",
    "def add_the_users_name(ctx: RunContext[ImageExtarctorHelper]) -> str:\n",
    "    #print(f\"the operator name is {ctx.deps} The image is {ctx.deps}.\")\n",
    "    #print(ctx)\n",
    "    return f\"the operator name is  {ctx.operator} The image url is {ctx.image_url}.\" #ctx.image_url\n",
    "#@support_agent.tool\n",
    "\n",
    "#print(add_the_users_name(ImageExtarctorHelper(operator=\"Bob\", image_url=ImageUrl(url=image_data))))\n",
    "\n",
    "# deps = ImageExtarctorHelper(operator=\"Bob\", image_url=image_data)\n",
    "deps = ImageExtarctorHelper(operator=\"Bob\", image_url=ImageUrl(url=image_data))\n",
    "#BinaryContent(data=image_response.content, media_type='image/png') )\n",
    "result = agentImage.run_sync('What my name?', deps=deps, \n",
    "                             #usage_limits=UsageLimits(response_tokens_limit=100),\n",
    "                            )\n",
    "\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51be056-7775-47b1-b916-ba5ff75c0d7c",
   "metadata": {},
   "source": [
    "GAP demmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ca45a-95b3-47de-974e-652f80ad77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persons=[Person(name='John', nickname='Johnny', email='john@example.com'), Person(name='Jane', nickname='Janie', email='jane@example.com'), Person(name='Boris', nickname='Invanovic', email='agent51@bunny.com')]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "\n",
    "class DatabaseConn:\n",
    "    \"\"\"This is a fake database for example purposes.\n",
    "\n",
    "    In reality, you'd be connecting to an external database\n",
    "    (e.g. PostgreSQL) to get information about customers.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    async def find_person(cls, *, name: str) -> Person | None:\n",
    "        if name == 'John':\n",
    "            return Person(name='John', nickname='Johnny', email='john@example.com')\n",
    "\n",
    "    @classmethod\n",
    "    async def add_person(cls, *, person: Person) -> Person | None:\n",
    "        print(f\"call add_person for {person}\")\n",
    "        knowledge_person.append(person)\n",
    "        return true\n",
    "            \n",
    "print(people)\n",
    "#print(f\"found persons: {knowledge_person_plain}\")\n",
    "\n",
    "message_persons =  PersonList(persons=[\n",
    "    {\"name\": \"Marco Polo\", \"nickname\": \"\", \"email\": \"Marco.Polo@wtc.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"},\n",
    "    {\"name\": \"Boris\", \"nickname\": \"Invanovic\", \"email\": \"agent51@bunny.com\"},\n",
    "])\n",
    "\n",
    "knowledge_person = PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"},\n",
    "    {\"name\": \"Boris\", \"nickname\": \"Invanovic\", \"email\": \"\"},\n",
    "])\n",
    "\n",
    "GAP_IMG_TEMPLATE_STR=\"\"\"\n",
    "You are a carefull analyst. \n",
    "wheck wich person are already known and which person are new in the message person list.\n",
    "Suggest the new persons, which could be added to the kwnon person list.\n",
    "\n",
    "You MUST only use person names provieded by the lists. Do not assume anything not provided by the input.\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class SupportDependencies:\n",
    "    model_config = ConfigDict(extra='ignore')\n",
    "    name: str\n",
    "    known_person: PersonList\n",
    "    message_person: PersonList\n",
    "    db: DatabaseConn\n",
    "\n",
    "# This pydantic model defines the structure of the result returned by the agent.\n",
    "class SupportResult(BaseModel):    \n",
    "    known_persons: PersonList = Field(description='The persons already known')\n",
    "    new_persons: PersonList = Field(description='The persons not yet known and candiates to add to the kwown person list')\n",
    "    \n",
    "\n",
    "\n",
    "#ollama_image_model = OpenAIModel(model_name=LLM_MODEL_VISUAL, base_url=f\"{OLLAMA_URL}/v1\",api_key=\"not-needed\")\n",
    "ollama_model = OpenAIModel(model_name=LLM_MODEL, base_url=f\"{OLLAMA_URL}/v1\")\n",
    "#ollama_gap_model = OpenAIModel(model=ollama_model, base_url=f\"{OLLAMA_URL}/v1\",api_key=\"not-needed\")\n",
    "\n",
    "gap_agent = Agent(\n",
    "    ollama_model,\n",
    "    deps_type=SupportDependencies,\n",
    "    # The response from the agent will, be guaranteed to be a SupportResult,\n",
    "    # if validation fails the agent is prompted to try again.\n",
    "    #result_type=SupportResult,\n",
    "    result_type=str,\n",
    "    system_prompt=GAP_IMG_TEMPLATE_STR,\n",
    "    retries=10,\n",
    ")\n",
    "\n",
    "@gap_agent.tool\n",
    "async def find_person(\n",
    "    ctx: RunContext[SupportDependencies]\n",
    ") -> float:\n",
    "    \"\"\"Returns if a Person if the person is found in the database.\"\"\"\n",
    "    # The docstring of a tool is also passed to the LLM as the description of the tool.\n",
    "    # Parameter descriptions are extracted from the docstring and added to the parameter schema sent to the LLM.\n",
    "    known_person = await ctx.deps.db.find_person(\n",
    "        name=ctx.deps.name,\n",
    "    )\n",
    "    return known_person\n",
    "\n",
    "@gap_agent.tool\n",
    "async def add_person(\n",
    "    tx: RunContext[SupportDependencies], new_person: Person\n",
    ") -> float:\n",
    "    \"\"\"Add a person to the database.\"\"\"\n",
    "    # The docstring of a tool is also passed to the LLM as the description of the tool.\n",
    "    # Parameter descriptions are extracted from the docstring and added to the parameter schema sent to the LLM.\n",
    "    ctx.deps.known_person.append(new_person) \n",
    "    return \"person added\"   \n",
    "\n",
    "deps = SupportDependencies(name=\"Frank\",known_person=knowledge_person, message_person=message_persons, db=DatabaseConn())\n",
    "result = await gap_agent.run('List all persons from the message_person list which are not known in the known_person list?', deps=deps)\n",
    "print(result.data)\n",
    "\n",
    "result = await gap_agent.run('call for each unknown person the fuction add_person to add them to the known person list?', deps=deps)\n",
    "print(result.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4926d7b-4d6c-4eed-b684-7eaf3b59f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "knowledge_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name=\"knowledge_tool\",\n",
    "    description=\"\"\"A RAG engine with some basic facts persons. Ask natural-language questions about persons and their properties and relations.\n",
    "              if the knowledge_tool has no relatied information, ignore the answer.\n",
    "              \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99ec6e-4c22-4b57-a1f3-2739012db474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "# generate_kwargs parameters are taken from https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\n",
    "def find_person(name: str, **kwargs):\n",
    "    \"\"\"\n",
    "    provides information about known persons. including ther detail information like birthdate\n",
    "\n",
    "    args:\n",
    "        name\n",
    "    \"\"\"\n",
    "    # Mock response; replace with real query logic\n",
    "    person_data = {\n",
    "        \"anna gölding\": {\"birthdate\": \"October 24, 1734\", \"known_for\": \"Last witch executed in Switzerland.\",\"object_id\":\"1234\",\"relations\":{\"knows other person\":\"ron paul\",\"organzation\":\"pilz mafia\"}},\n",
    "        \"john doe\": {\"birthdate\": \"Unknown\", \"known_for\": \"Placeholder name for anonymous individuals.\"},\n",
    "        \"ron paul\": {\"birthdate\": \"May 1, 1928\", \"known_for\": \"Talking a lot.\"},\n",
    "        \"miranda meyers\": {\"birthdate\": \"Aug 11, 1998\", \"known_for\": \"Miranda verkauft gerne verdorbens Eis. Das Eis erhält sie illegal von Litauen, wo es mit Mäusemilch hergestellt wird.\"},\n",
    "    }\n",
    "    return person_data.get(name.lower(), \"No information available for this person.\")\n",
    "\n",
    "find_person_tool = FunctionTool.from_defaults(\n",
    "    fn=find_person,\n",
    "    name=\"find_person\",\n",
    ")\n",
    "\n",
    "\n",
    "def find_organization(name: str, **kwargs):\n",
    "    \"\"\"\n",
    "    provides information about known official and inofficial organzations.\n",
    "\n",
    "    args:\n",
    "        name\n",
    "    \"\"\"\n",
    "    # Mock response; replace with real query logic\n",
    "    org_data  = {\n",
    "        \"un\": {\"name\": \"United Nations\", \"description\": \"The Security Council has primary responsibility for the maintenance of international peace and security.\",\"id\":\"200\",\"relations\":{\"\"}},\n",
    "        \"pilz mafia\": {\"name\": \"Pilz Mafia\", \"description\": \"\",\"id\":\"201\",\"members\":{\"anna gölding\",\"ron paul\"}},\n",
    "        \"acme company\": {\"name\":\"acme company\",\"description\":\"placeholder company\"},\n",
    "    }\n",
    "    return org_data.get(name.lower(), \"No information available for this organization.\")\n",
    "\n",
    "find_orgnization_tool = FunctionTool.from_defaults(\n",
    "    fn=find_organization,\n",
    "    name=\"find_organization\",\n",
    ")\n",
    "\n",
    "#def get_messages(name: str, min_daterange: datetime, max_daterange: datetime):\n",
    "def get_messages(name: str, min_daterange: str, max_daterange: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Retrieve information about communications between two or more people within a given date range.\n",
    "\n",
    "    # Example usage:\n",
    "        name = \"c1\"\n",
    "        min_daterange = ISO8601 date string\n",
    "        max_daterange = ISO8601 date string\n",
    "        messages = get_messages(name, min_daterange, max_daterange)\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the context always use c1.\n",
    "        min_daterange (datetime): The start of the date range.\n",
    "        max_daterange (datetime): The end of the date range.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of messages for the given name within the date range.\n",
    "    \"\"\"\n",
    "    # Mock response; replace with real query logic\n",
    "    min_daterange_ts = parser.parse(min_daterange)\n",
    "    max_daterange_ts = parser.parse(max_daterange)\n",
    "    org_data = {\n",
    "        \"c1_1738446338\": {\"sender\": \"Ron Paul\", \"message\": \"Anna Gölding ist gestorben.\", \"timestamp\": datetime(2025, 1, 1)},\n",
    "        \"c1_1738446338\": {\"sender\": \"Pilz Mafia\", \"message\": \"Hat Sie mit Boris Weed gesprochen oder ihn erwähnt? Sie wollte von ihm ein Sack voll Vogelfutter kaufen.\", \"timestamp\": datetime(2025, 1, 5)},\n",
    "    }\n",
    "\n",
    "    result = {}\n",
    "    for key, value in org_data.items():\n",
    "        if key.startswith(name.lower()): # and min_daterange_ts <= value[\"timestamp\"] <= max_daterange_ts:\n",
    "            result[key] = value\n",
    "\n",
    "    if not result:\n",
    "        return \"No information available for this timerange\"\n",
    "\n",
    "    return result\n",
    "\n",
    "get_messages_tool = FunctionTool.from_defaults(\n",
    "    fn=get_messages,\n",
    "    name=\"get_messages\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee7b71-0c6d-40f0-9a5a-73a98d3619ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    find_person_tool,\n",
    "    find_orgnization_tool,\n",
    "    get_messages_tool,\n",
    "    knowledge_tool,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be71922-bd13-4cfe-96ae-f1864623edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "prod_data = [\"Die Pilz Mafia ist eine Organisation.\", \"Die Polnische Polizei überwacht die Pilz Mafia.\"]\n",
    "\n",
    "org_result = agent.run_sync(f'What organizations are mentioned {prod_data}')\n",
    "print(org_result.data)\n",
    "print(org_result.usage())\n",
    "#memory.save(org_result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd38bdc-5ca4-4ee4-aaef-c9547d44e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.memory import ChatMemoryBuffer, ChatSummaryMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer(token_limit=2000)\n",
    "agent = ReActAgent.from_tools(tools, llm=llm, verbose=True, context=context, tool_choice='auto',max_iterations=25, timeout=3000, memory=memory) #, chat_history=memory)\n",
    "\n",
    "# update agent system prompt\n",
    "react_system_prompt = PromptTemplate(react_system_header_str)\n",
    "agent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})\n",
    "agent.reset()\n",
    "print(\"start prompt\")\n",
    "#prompt = \"Who is Anna Gölding and what other person may be related to her? to which organzations may she be related?\"\n",
    "question_context = \"\"\"context: c1, zeitbereich: 2025-02-01T00:00:00+00:00 to 2025-02-15T00:00:00+00:00\"\"\"\n",
    "prompt = f\"\"\"Wer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\"\"\"\n",
    "xprompt = f\"\"\"Wer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\n",
    "             Liste alle informationen und fakten die du findest in der antwort auf.\n",
    "            questions context: {question_context}\n",
    "            1. Analysiere die Person bekannt ist im find person tool.\n",
    "            2. Analysiere die Person verbindungen zu anderen Personen oder Organisationen hat\n",
    "            3. Prüfe ob Nachriten (messages) im context dieser Personen im gesuchten Zeitbereich statgefunden haben mit dem get_messages tool.\n",
    "            4. Nenne die Anzahl der conversationen\n",
    "            5. Nenne die Teilnehmer der conversationen\n",
    "            6. Fasse den Inhalt der Kommunikation zusammen\n",
    "            7. Prüfe ob Entitäten wie Personen, Organisationen oder Orte in der Nachrichten vorkommen, die bisher nicht bekannt sind.\n",
    "            8. Kontrolliere ob alle Punkte dieser liste erfüllt sind\n",
    "          \"\"\"\n",
    "response = agent.query(prompt)\n",
    "#response = llm.complete(prompt)\n",
    "\n",
    "#memory.save_context({\"input\": prompt}, {\"output\": str(response)})\n",
    "\n",
    "print(f\"AI: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
