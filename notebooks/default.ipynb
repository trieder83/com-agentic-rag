{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fb7419-0dbf-43d6-a734-25d0f3f224b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ollama-service-internal.default.svc.cluster.local:11433\n",
      "model: llama3.2:3b\n",
      "embedding: bge-m3:567m\n",
      "datapath /app/data\n",
      "no_proxy None\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OLLAMA_URL=os.getenv(\"OLLAMA_URL\")\n",
    "LLM_MODEL=os.getenv(\"LLM_MODEL\")\n",
    "EMBEDDING_MODEL=os.getenv(\"EMBEDDING_MODEL\")\n",
    "DATAPATH=os.getenv(\"DATAPATH\")\n",
    "#OLLAMA_URL='http://localhost:11434'\n",
    "#LLM_MODEL=\"llama3.2:3b\" # max retires\n",
    "# LLM_MODEL=\"gemma3:4b\" # no tool support\n",
    "#LLM_MODEL=\"qwen2.5-coder:1.5b\" # no tool support\n",
    "#LLM_MODEL=\"deepseek-r1:1.5b\" # does not support tools\n",
    "#os.setenv(\"no_proxy=localhost,127.0.0.1,*.my-it-solutions.net,ollama\")\n",
    "\n",
    "print(OLLAMA_URL)\n",
    "print(f\"model: {LLM_MODEL}\")\n",
    "print(f\"embedding: {EMBEDDING_MODEL}\")\n",
    "print(f\"datapath {DATAPATH}\")\n",
    "print(f\"no_proxy {os.getenv('no_proxy')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40791bb1-6938-4a26-9265-c67379d6e9a1",
   "metadata": {},
   "source": [
    "Test connection to ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c54e76c-e63d-485f-a9d1-9ea9340f620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "response = requests.get(OLLAMA_URL,timeout=3)\n",
    "if response.status_code == requests.codes.ok:\n",
    "    print(response)\n",
    "else:\n",
    "    print(response)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745ca59-a6ee-4b16-bb75-3eb1a84c746f",
   "metadata": {},
   "source": [
    "Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154bcc6a-e579-4df6-a16a-12462812569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /opt/venv/lib/python3.13/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=LLM_MODEL, request_timeout=120.0, base_url=OLLAMA_URL, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce0e5e0-b2b3-4f0c-bd2a-0db511420163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[f\"{DATAPATH}/testdata.txt\",f\"{DATAPATH}/additionalinfo.txt\"]\n",
    ").load_data()\n",
    "print(\"loaded\")\n",
    "\n",
    "Settings.embed_model = OllamaEmbedding(model_name=EMBEDDING_MODEL, base_url=OLLAMA_URL,embed_batch_size=100)\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=30)\n",
    "# ollama\n",
    "Settings.llm = llm\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "documents,\n",
    "#embed_model=ollama_embedding,\n",
    ")\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1235f-5d7d-4a7d-aa28-208a5c750fc1",
   "metadata": {},
   "source": [
    "Demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4723fe57-a7aa-4429-a2fc-6c83e56be0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{ \"From\": \"Marco.Polo@wtc.com<Marco Polo>\", \"To\": \"Boris@arm.ru<Boris Invanovic>\", \"Subject\": \"Lieferung\", \n",
    "            \"Content\": \"Eine neue Lieferung steht bereit. Wir senden sie morge mit dem Flug TK9518 nach BEG\"}\n",
    "            ,{ \"From\": \"Boris@arm.ru<Boris Invanovic>\", \"To\": \"Chef51@mega.de\", \"Subject\": \"Info\", \n",
    "            \"Content\": \"Morgen können die neuen Bananen in BEG abgeholt werden. Grüsse Bo\"} #nick name Bo\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca1f13-3824-4b0c-a513-a92ba7480766",
   "metadata": {},
   "source": [
    "Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c78c7ba-65cd-406e-92a7-c0465f5825ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Person entity.\"\"\"\n",
    "    name: str = Field(\n",
    "        ..., description=\"The name of a person\"\n",
    "    )\n",
    "    nickname: str = Field(\n",
    "        ..., description=\"The nickname of a person\"\n",
    "    )\n",
    "    email: str = Field(\n",
    "        ..., description=\"The email address of a person\"\n",
    "    )    \n",
    "\n",
    "class Organization(BaseModel):\n",
    "    \"\"\"Organization entity\"\"\"\n",
    "    name: str\n",
    "\n",
    "class PersonList(BaseModel):\n",
    "    persons: List[Person]\n",
    "    \n",
    "class OrganizationList(BaseModel):        \n",
    "    organizations: List[Organization]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_person_list(new_persons: PersonList, existing_list: Optional[PersonList] = None) -> PersonList:\n",
    "    \"\"\"\n",
    "    Add a person list to an empty or existing array of persons.\n",
    "    \n",
    "    Args:\n",
    "        new_persons: A PersonList object containing persons to be added\n",
    "        existing_list: An optional existing PersonList object to add to\n",
    "    \n",
    "    Returns:\n",
    "        A new PersonList containing the merged list of persons\n",
    "    \"\"\"\n",
    "    if existing_list is None:\n",
    "        return new_persons\n",
    "    \n",
    "    # Create a new list with all persons from both lists\n",
    "    merged_persons = PersonList(persons=existing_list.persons + new_persons.persons)\n",
    "    return merged_persons   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ac488f-208b-40cf-a697-ddebc89c735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persons=[Person(name='John', nickname='Johnny', email='john@example.com'), Person(name='Jane', nickname='Janie', email='jane@example.com')]\n",
      "name='John Doe' nickname='Johnny' email='john@example.com'\n",
      "name='Bob Johnson' nickname='Bobby' email='bob@example.com'\n"
     ]
    }
   ],
   "source": [
    "# Knowledge base\n",
    "import json\n",
    "knowledge_person = []\n",
    "knowledge_person_plain = []\n",
    "\n",
    "#add_person_list(PersonList(Person=[{\"name\":\"Mario\",\"nickname\":\"MarioBo\",\"email\":\"ma@acme.com\"}]).Person,knowledge_person)\n",
    "\n",
    "people = PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"},\n",
    "])\n",
    "print(people)\n",
    "                    \n",
    "person = Person(\n",
    "    name=\"John Doe\",\n",
    "    nickname=\"Johnny\",\n",
    "    email=\"john@example.com\"\n",
    ")\n",
    "print(person)\n",
    "json_data = '{\"name\": \"Bob Johnson\", \"nickname\": \"Bobby\", \"email\": \"bob@example.com\"}'\n",
    "data_dict = json.loads(json_data)\n",
    "person = Person.model_validate(data_dict)\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c242d2c-9111-4b43-a2de-ddaf310cddf8",
   "metadata": {},
   "source": [
    "Save new entities to memmory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "793d9a06-82c1-4076-b7dc-5ea577f26bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: {'From': 'Marco.Polo@wtc.com<Marco Polo>', 'To': 'Boris@arm.ru<Boris Invanovic>', 'Subject': 'Lieferung', 'Content': 'Eine neue Lieferung steht bereit. Wir senden sie morge mit dem Flug TK9518 nach BEG'}\n",
      "```\n",
      "json\n",
      "PersonList(persons=[\n",
      "    {\"name\": \"Marco Polo\", \"nickname\": \"Marco Polo\", \"email\": \"Marco.Polo@wtc.com\"},\n",
      "    {\"name\": \"Boris Invanovic\", \"nickname\": \"Boris\", \"email\": \"Boris@arm.ru\"}\n",
      "])\n",
      "```\n",
      "```\n",
      "json\n",
      "PersonList(persons=[\n",
      "    {\"name\": \"Marco Polo\", \"nickname\": \"Marco Polo\", \"email\": \"Marco.Polo@wtc.com\"},\n",
      "    {\"name\": \"Boris Invanovic\", \"nickname\": \"Boris\", \"email\": \"Boris@arm.ru\"}\n",
      "])\n",
      "```\n",
      "***\n",
      "query: {'From': 'Boris@arm.ru<Boris Invanovic>', 'To': 'Chef51@mega.de', 'Subject': 'Info', 'Content': 'Morgen können die neuen Bananen in BEG abgeholt werden. Grüsse Bo'}\n",
      "json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Boris Invanovic\",\n",
      "    \"nickname\": \"Boris\",\n",
      "    \"email\": \"Boris@arm.ru\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"\",\n",
      "    \"nickname\": \"\",\n",
      "    \"email\": \"\"\n",
      "  }\n",
      "]\n",
      "json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Boris Invanovic\",\n",
      "    \"nickname\": \"Boris\",\n",
      "    \"email\": \"Boris@arm.ru\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"\",\n",
      "    \"nickname\": \"\",\n",
      "    \"email\": \"\"\n",
      "  }\n",
      "]\n",
      "***\n",
      "------------------\n",
      "['```\\njson\\nPersonList(persons=[\\n    {\"name\": \"Marco Polo\", \"nickname\": \"Marco Polo\", \"email\": \"Marco.Polo@wtc.com\"},\\n    {\"name\": \"Boris Invanovic\", \"nickname\": \"Boris\", \"email\": \"Boris@arm.ru\"}\\n])\\n```', 'json\\n[\\n  {\\n    \"name\": \"Boris Invanovic\",\\n    \"nickname\": \"Boris\",\\n    \"email\": \"Boris@arm.ru\"\\n  },\\n  {\\n    \"name\": \"\",\\n    \"nickname\": \"\",\\n    \"email\": \"\"\\n  }\\n]']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.program.openai import OpenAIPydanticProgram\n",
    "from llama_index.core.extractors import PydanticProgramExtractor\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "EXTRACT_TEMPLATE_STR = \"\"\"\\\n",
    "Here is the content of the section:\n",
    "----------------\n",
    "{context_str}\n",
    "----------------\n",
    "Given the contextual information, extract out all person object.\n",
    "A Person entity consists of: name, email.\n",
    "Only use the context information. Do not assume any other facts.\n",
    "Your output MUST follow this json EXACT format with EXACT field names:\\n\\n\n",
    "[{\"Persons:[{\"name\":\"Person Name\"},{\"email\":[Email address],\"nickname\":{Nickname}}}]}  ]\n",
    "\\\n",
    "\"\"\"\n",
    "\n",
    "EXTRACT_TEMPLATE_STR1 = \"\"\"\\\n",
    "Given the contextual information, extract a list of persons.\n",
    "If no persons are found return an emtpy list.\n",
    "Only use the context information. Do not assume any other facts.\n",
    "Your output MUST follow this json EXACT format with EXACT field names:\\n\\n\n",
    "PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"},\n",
    "])\n",
    "The output MUST be always a JSON Array.\n",
    "Only respond in the correct format, do not include additional properties in the JSON.\\n\n",
    "\"\"\"\n",
    "EXTRACT_TEMPLATE_STR2 = \"\"\"\\\n",
    "From the provided context, extract a list of persons mentioned in the text.\n",
    "\n",
    "Each person MUST include:\n",
    "\"name\": Full name of the person.\n",
    "\"nickname\": Nickname if mentioned, otherwise use an empty string \"\".\n",
    "\"email\": Email address if mentioned, otherwise use an empty string \"\".\n",
    "Constraints:\n",
    "\n",
    "Do NOT assume or invent any information not explicitly present in the context.\n",
    "If no persons are found, return an empty list: PersonList(persons=[]).\n",
    "Always respond with ONLY valid JSON following this EXACT structure (no extra text, no explanations):\n",
    "json\n",
    "Copy\n",
    "Edit\n",
    "PersonList(persons=[\n",
    "    {\"name\": \"John\", \"nickname\": \"Johnny\", \"email\": \"john@example.com\"},\n",
    "    {\"name\": \"Jane\", \"nickname\": \"Janie\", \"email\": \"jane@example.com\"}\n",
    "])\n",
    "All fields MUST be present for each person, even if empty.\n",
    "The output MUST always be a valid JSON array inside PersonList, even when empty.\n",
    "Context to analyze:\n",
    "\"\"\"\n",
    "\n",
    "# extract only entities\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "ollama_model = OpenAIModel(model_name=LLM_MODEL, base_url=f\"{OLLAMA_URL}/v1\")\n",
    "                     \n",
    "#agent = Agent(model=ollama_model, result_type=str,system_prompt=EXTRACT_TEMPLATE_STR,retries=3)\n",
    "# deps_tpye is the input \n",
    "#agent = Agent(model=ollama_model,result_type=PersonList,deps_type=str,system_prompt=EXTRACT_TEMPLATE_STR1,retries=4)\n",
    "agent = Agent(model=ollama_model,result_type=str,deps_type=str,system_prompt=EXTRACT_TEMPLATE_STR2,retries=1)\n",
    "#TODO\n",
    "\n",
    "#import json\n",
    "#PersonList_schema = PersonList.model_json_schema()  # (1)!\n",
    "#print(json.dumps(PersonList_schema, indent=2))  # (2)!\n",
    "#print(json.dump())\n",
    "knowledge_person_plain = []\n",
    "for message in messages:\n",
    "    print(f\"query: {message}\")\n",
    "    entity_result = agent.run_sync(f\"{message}\")\n",
    "    print(entity_result.data) \n",
    "    #print(len(entity_result.data))\n",
    "    if isinstance(entity_result, PersonList):\n",
    "        add_person_list(knowledge_person.data)\n",
    "    if len(entity_result.data) > 2:        \n",
    "        knowledge_person_plain.append(entity_result.data)\n",
    "        print(entity_result.data)\n",
    "    print(\"***\")\n",
    "\n",
    "print(\"------------------\")\n",
    "print(knowledge_person_plain)\n",
    "#print(entity_result.data)\n",
    "#print(entity_result.usage())\n",
    "#memory.save(org_result.data)\n",
    "\n",
    "#print(entity_result.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e9cb1-cff2-446b-9328-d09e362d7510",
   "metadata": {},
   "source": [
    "Relation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "398b433a-ec9f-4d5d-862a-32d8b560beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"graph\": {\n",
      "        \"nodes\": {\n",
      "            \"Marco Polo\": {\n",
      "                \"name\": \"Marco Polo\"\n",
      "            },\n",
      "            \"Boris Invanovic\": {\n",
      "                \"name\": \"Boris Invanovic\",\n",
      "                \"email\": \"Boris@arm.ru\"\n",
      "            }\n",
      "        },\n",
      "        \"edges\": [\n",
      "            {\n",
      "                \"source\": \"Marco Polo\",\n",
      "                \"target\": \"Boris Invanovic\",\n",
      "                \"relation\": \"talk\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# relation talk / known\n",
    "\n",
    "RELATE_TEMPLATE_STR = f\"\"\"\\\n",
    "Task:\n",
    "From the provided data, extract a graph of persons and their relationships.\n",
    "\n",
    "Graph structure:\n",
    "\n",
    "Nodes: Each person identified in the \"Entities to analyze\".\n",
    "Edges: Represent relationships between persons based on message content.\n",
    "Types of relations (edges):\n",
    "\n",
    "\"talk\": Two persons talk directly to each other.\n",
    "\"known\": The content indicates that one person knows another (e.g., mentions them as a known contact, friend, colleague).\n",
    "Constraints and Output Rules:\n",
    "\n",
    "ONLY use persons listed under \"Entities to analyze\" for nodes. Do not invent persons.\n",
    "If no relations are found, return an empty \"edges\" list.\n",
    "Always return a valid JSON object matching EXACTLY the structure shown in the example.\n",
    "DO NOT add any explanatory text or comments. Only output the JSON.\n",
    "All node IDs must match person names exactly as listed in \"Entities to analyze\" (case sensitive).\n",
    "\n",
    "Example output:\n",
    "\n",
    "json\n",
    "Copy\n",
    "Edit\n",
    "{{\n",
    "  \"graph\": {{\n",
    "    \"nodes\": {{\n",
    "      \"Person1\": {{\"name\": \"John\"}},\n",
    "      \"Person2\": {{\"name\": \"Alice\"}}\n",
    "    }},\n",
    "    \"edges\": [\n",
    "      {{\n",
    "        \"source\": \"Person1\",\n",
    "        \"target\": \"Person2\",\n",
    "        \"relation\": \"talk\"\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "Important:\n",
    "\n",
    "Use exact names from \"Entities to analyze\" as node IDs.\n",
    "Always include all persons as nodes, even if they have no edges.\n",
    "Follow exact JSON field names and structure as shown.\n",
    "\n",
    "\n",
    "Data to analyze:\n",
    "\"\"\"\n",
    "\n",
    "rel_agent = Agent(model=ollama_model,result_type=str,deps_type=str,system_prompt=RELATE_TEMPLATE_STR,retries=1)\n",
    "knowledge_person_plain\n",
    "\n",
    "relation_result = rel_agent.run_sync(f\"\"\"{messages} entities: {knowledge_person_plain}\"\"\")\n",
    "\n",
    "#print(relation_result)\n",
    "print(json.dumps(json.loads(relation_result.data), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24796ff4-0373-464e-825c-ee751b20bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /opt/venv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Your graph JSON data ---\n",
    "graph_data = json.loads(relation_result.data)\n",
    "\n",
    "# --- Step 2: Create a NetworkX graph ---\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for node_id, node_info in graph_data[\"graph\"][\"nodes\"].items():\n",
    "    label = node_info[\"name\"]\n",
    "    nickname = node_info.get(\"nickname\", \"\")\n",
    "    if nickname:\n",
    "        label += f' (\"{nickname}\")'  # Append nickname if available\n",
    "    G.add_node(node_id, label=label)\n",
    "\n",
    "# Add edges with relation as attribute\n",
    "for edge in graph_data[\"graph\"][\"edges\"]:\n",
    "    G.add_edge(edge[\"source\"], edge[\"target\"], relation=edge[\"relation\"])\n",
    "\n",
    "# --- Step 3: Draw the graph ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Positions for all nodes\n",
    "pos = nx.spring_layout(G, seed=42)  # seed for reproducibility\n",
    "\n",
    "# Draw nodes and labels\n",
    "nx.draw_networkx_nodes(G, pos, node_color='skyblue', node_size=2000)\n",
    "nx.draw_networkx_labels(G, pos, labels={n: d['label'] for n, d in G.nodes(data=True)}, font_size=12)\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, width=2, edge_color='gray')\n",
    "\n",
    "# Draw edge labels (relation type)\n",
    "edge_labels = nx.get_edge_attributes(G, 'relation')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red', font_size=10)\n",
    "\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title('Person Relation Graph', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdde2824-ff36-4245-891d-73825b3a9208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current date is: 2025-03-13\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from pydantic_ai import RunContext\n",
    "\n",
    "@agent.system_prompt\n",
    "def add_the_date() -> str:  \n",
    "    return f'The date is {date.today()}.'\n",
    "\n",
    "result = agent.run_sync('What is the date?', deps='Frank')\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2df31d-f665-479f-bbc9-895ef993f42a",
   "metadata": {},
   "source": [
    "Extract data from image (only works with a model supporting images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd9d5dd3-9663-4a8a-a551-b61797a29b4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelHTTPError",
     "evalue": "status_code: 400, model_name: llama3.2:3b, body: {'message': 'invalid image input', 'type': 'invalid_request_error', 'param': None, 'code': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/models/openai.py:274\u001b[39m, in \u001b[36mOpenAIModel._completions_create\u001b[39m\u001b[34m(self, messages, stream, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(\n\u001b[32m    275\u001b[39m         model=\u001b[38;5;28mself\u001b[39m._model_name,\n\u001b[32m    276\u001b[39m         messages=openai_messages,\n\u001b[32m    277\u001b[39m         n=\u001b[32m1\u001b[39m,\n\u001b[32m    278\u001b[39m         parallel_tool_calls=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    279\u001b[39m         tools=tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    280\u001b[39m         tool_choice=tool_choice \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    281\u001b[39m         stream=stream,\n\u001b[32m    282\u001b[39m         stream_options={\u001b[33m'\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m NOT_GIVEN,\n\u001b[32m    283\u001b[39m         max_tokens=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    284\u001b[39m         temperature=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    285\u001b[39m         top_p=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    286\u001b[39m         timeout=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    287\u001b[39m         seed=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    288\u001b[39m         presence_penalty=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    289\u001b[39m         frequency_penalty=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    290\u001b[39m         logit_bias=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    291\u001b[39m         reasoning_effort=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mopenai_reasoning_effort\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    292\u001b[39m     )\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:2000\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1999\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2000\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2001\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2002\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2003\u001b[39m         {\n\u001b[32m   2004\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2005\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2006\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2007\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2008\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2009\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2010\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2011\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2012\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2013\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2014\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2015\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2016\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2017\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2018\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2019\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2020\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2021\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2022\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2023\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2024\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2025\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2026\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2027\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2028\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2029\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2030\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2031\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2032\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2033\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2034\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2035\u001b[39m         },\n\u001b[32m   2036\u001b[39m         completion_create_params.CompletionCreateParams,\n\u001b[32m   2037\u001b[39m     ),\n\u001b[32m   2038\u001b[39m     options=make_request_options(\n\u001b[32m   2039\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2040\u001b[39m     ),\n\u001b[32m   2041\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2042\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2043\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2044\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/openai/_base_client.py:1767\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1764\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1765\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1766\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/openai/_base_client.py:1461\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1459\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1462\u001b[39m     cast_to=cast_to,\n\u001b[32m   1463\u001b[39m     options=options,\n\u001b[32m   1464\u001b[39m     stream=stream,\n\u001b[32m   1465\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1466\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1467\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/openai/_base_client.py:1562\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1561\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1565\u001b[39m     cast_to=cast_to,\n\u001b[32m   1566\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1570\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1571\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'invalid image input', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModelHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      2\u001b[39m EXTRACT_IMG_TEMPLATE_STR = \u001b[33m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33mExtract all possible information from the image.\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m----------------\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m agentImage = Agent(model=ollama_model,result_type=Person,system_prompt=EXTRACT_IMG_TEMPLATE_STR,retries=\u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result = \u001b[43magentImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mImageUrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile:///data/img/DO_UKR_AV.jpg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:558\u001b[39m, in \u001b[36mAgent.run_sync\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m infer_name \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:316\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    307\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    308\u001b[39m     result_type=result_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     usage=usage,\n\u001b[32m    315\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (final_result := agent_run.result) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mThe graph run did not finish properly\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:1366\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1364\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, ResultDataT] | End[FinalResult[ResultDataT]]:\n\u001b[32m   1365\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1366\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(next_node):\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:736\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:725\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    722\u001b[39m state = \u001b[38;5;28mself\u001b[39m.state\n\u001b[32m    723\u001b[39m deps = \u001b[38;5;28mself\u001b[39m.deps\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.graph.next(node, history, state=state, deps=deps, infer_name=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:307\u001b[39m, in \u001b[36mGraph.next\u001b[39m\u001b[34m(self, node, history, state, deps, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     start_ts = _utils.now_utc()\n\u001b[32m    306\u001b[39m     start = perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    308\u001b[39m     duration = perf_counter() - start\n\u001b[32m    310\u001b[39m history.append(\n\u001b[32m    311\u001b[39m     NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=\u001b[38;5;28mself\u001b[39m.snapshot_state)\n\u001b[32m    312\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:252\u001b[39m, in \u001b[36mModelRequestNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._did_stream:\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# `self._result` gets set when exiting the `stream` contextmanager, so hitting this\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;66;03m# means that the stream was started but not finished before `run()` was called\u001b[39;00m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.AgentRunError(\u001b[33m'\u001b[39m\u001b[33mYou must finish streaming before calling run()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_request(ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:304\u001b[39m, in \u001b[36mModelRequestNode._make_request\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    303\u001b[39m model_settings, model_request_parameters = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_request(ctx)\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m model_response, request_usage = \u001b[38;5;28;01mawait\u001b[39;00m ctx.deps.model.request(\n\u001b[32m    305\u001b[39m     ctx.state.message_history, model_settings, model_request_parameters\n\u001b[32m    306\u001b[39m )\n\u001b[32m    307\u001b[39m ctx.state.usage.incr(_usage.Usage(), requests=\u001b[32m1\u001b[39m)\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish_handling(ctx, model_response, request_usage)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/models/openai.py:202\u001b[39m, in \u001b[36mOpenAIModel.request\u001b[39m\u001b[34m(self, messages, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    197\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[ModelMessage],\n\u001b[32m    198\u001b[39m     model_settings: ModelSettings | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    199\u001b[39m     model_request_parameters: ModelRequestParameters,\n\u001b[32m    200\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ModelResponse, usage.Usage]:\n\u001b[32m    201\u001b[39m     check_allow_model_requests()\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._completions_create(\n\u001b[32m    203\u001b[39m         messages, \u001b[38;5;28;01mFalse\u001b[39;00m, cast(OpenAIModelSettings, model_settings \u001b[38;5;129;01mor\u001b[39;00m {}), model_request_parameters\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(response), _map_usage(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/models/openai.py:295\u001b[39m, in \u001b[36mOpenAIModel._completions_create\u001b[39m\u001b[34m(self, messages, stream, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (status_code := e.status_code) >= \u001b[32m400\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ModelHTTPError(status_code=status_code, model_name=\u001b[38;5;28mself\u001b[39m.model_name, body=e.body) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mModelHTTPError\u001b[39m: status_code: 400, model_name: llama3.2:3b, body: {'message': 'invalid image input', 'type': 'invalid_request_error', 'param': None, 'code': None}"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import ImageUrl\n",
    "EXTRACT_IMG_TEMPLATE_STR = \"\"\"\\\n",
    "Extract all possible information from the image.\n",
    "----------------\n",
    "{context_str}\n",
    "----------------\n",
    "A Person entity consists of: name, email.\n",
    "Only use the context information. Do not assume any other facts.\n",
    "Your output MUST follow this json EXACT format with EXACT field names:\\n\\n\n",
    "{\"persons:[{\"name\":[Person Name]},{\"email\":[Email address],\"birthdate\":[birthdate],\"nationality\":[nationality]}]}  \n",
    "\\\n",
    "\"\"\"\n",
    "agentImage = Agent(model=ollama_model,result_type=Person,system_prompt=EXTRACT_IMG_TEMPLATE_STR,retries=3)\n",
    "result = agentImage.run_sync(\n",
    "    [\n",
    "        '',\n",
    "        ImageUrl(url='file:///data/img/DO_UKR_AV.jpg'),\n",
    "    ]\n",
    ")\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507a430-08ee-4cbe-9c74-c96dcca47fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_core import to_jsonable_python\n",
    "from pydantic_ai.messages import ModelMessagesTypeAdapter\n",
    "\n",
    "history_step_1 = entity_result.all_messages()\n",
    "as_python_objects = to_jsonable_python(history_step_1)  \n",
    "same_history_as_step_1 = ModelMessagesTypeAdapter.validate_python(as_python_objects)\n",
    "\n",
    "entity_result2 = agent.run_sync(  \n",
    "    f'add entities from this message: {message2}', message_history=same_history_as_step_1\n",
    ")\n",
    "\n",
    "print(entity_result2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4926d7b-4d6c-4eed-b684-7eaf3b59f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "knowledge_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name=\"knowledge_tool\",\n",
    "    description=\"\"\"A RAG engine with some basic facts persons. Ask natural-language questions about persons and their properties and relations.\n",
    "              if the knowledge_tool has no relatied information, ignore the answer.\n",
    "              \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e99ec6e-4c22-4b57-a1f3-2739012db474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "# generate_kwargs parameters are taken from https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\n",
    "def find_person(name: str, **kwargs):\n",
    "    \"\"\"\n",
    "    provides information about known persons. including ther detail information like birthdate\n",
    "\n",
    "    args:\n",
    "        name\n",
    "    \"\"\"\n",
    "    # Mock response; replace with real query logic\n",
    "    person_data = {\n",
    "        \"anna gölding\": {\"birthdate\": \"October 24, 1734\", \"known_for\": \"Last witch executed in Switzerland.\",\"object_id\":\"1234\",\"relations\":{\"knows other person\":\"ron paul\",\"organzation\":\"pilz mafia\"}},\n",
    "        \"john doe\": {\"birthdate\": \"Unknown\", \"known_for\": \"Placeholder name for anonymous individuals.\"},\n",
    "        \"ron paul\": {\"birthdate\": \"May 1, 1928\", \"known_for\": \"Talking a lot.\"},\n",
    "        \"miranda meyers\": {\"birthdate\": \"Aug 11, 1998\", \"known_for\": \"Miranda verkauft gerne verdorbens Eis. Das Eis erhält sie illegal von Litauen, wo es mit Mäusemilch hergestellt wird.\"},\n",
    "    }\n",
    "    return person_data.get(name.lower(), \"No information available for this person.\")\n",
    "\n",
    "find_person_tool = FunctionTool.from_defaults(\n",
    "    fn=find_person,\n",
    "    name=\"find_person\",\n",
    ")\n",
    "\n",
    "\n",
    "def find_organization(name: str, **kwargs):\n",
    "    \"\"\"\n",
    "    provides information about known official and inofficial organzations.\n",
    "\n",
    "    args:\n",
    "        name\n",
    "    \"\"\"\n",
    "    # Mock response; replace with real query logic\n",
    "    org_data  = {\n",
    "        \"un\": {\"name\": \"United Nations\", \"description\": \"The Security Council has primary responsibility for the maintenance of international peace and security.\",\"id\":\"200\",\"relations\":{\"\"}},\n",
    "        \"pilz mafia\": {\"name\": \"Pilz Mafia\", \"description\": \"\",\"id\":\"201\",\"members\":{\"anna gölding\",\"ron paul\"}},\n",
    "        \"acme company\": {\"name\":\"acme company\",\"description\":\"placeholder company\"},\n",
    "    }\n",
    "    return org_data.get(name.lower(), \"No information available for this organization.\")\n",
    "\n",
    "find_orgnization_tool = FunctionTool.from_defaults(\n",
    "    fn=find_organization,\n",
    "    name=\"find_organization\",\n",
    ")\n",
    "\n",
    "#def get_messages(name: str, min_daterange: datetime, max_daterange: datetime):\n",
    "def get_messages(name: str, min_daterange: str, max_daterange: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Retrieve information about communications between two or more people within a given date range.\n",
    "\n",
    "    # Example usage:\n",
    "        name = \"c1\"\n",
    "        min_daterange = ISO8601 date string\n",
    "        max_daterange = ISO8601 date string\n",
    "        messages = get_messages(name, min_daterange, max_daterange)\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the context always use c1.\n",
    "        min_daterange (datetime): The start of the date range.\n",
    "        max_daterange (datetime): The end of the date range.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of messages for the given name within the date range.\n",
    "    \"\"\"\n",
    "    # Mock response; replace with real query logic\n",
    "    min_daterange_ts = parser.parse(min_daterange)\n",
    "    max_daterange_ts = parser.parse(max_daterange)\n",
    "    org_data = {\n",
    "        \"c1_1738446338\": {\"sender\": \"Ron Paul\", \"message\": \"Anna Gölding ist gestorben.\", \"timestamp\": datetime(2025, 1, 1)},\n",
    "        \"c1_1738446338\": {\"sender\": \"Pilz Mafia\", \"message\": \"Hat Sie mit Boris Weed gesprochen oder ihn erwähnt? Sie wollte von ihm ein Sack voll Vogelfutter kaufen.\", \"timestamp\": datetime(2025, 1, 5)},\n",
    "    }\n",
    "\n",
    "    result = {}\n",
    "    for key, value in org_data.items():\n",
    "        if key.startswith(name.lower()): # and min_daterange_ts <= value[\"timestamp\"] <= max_daterange_ts:\n",
    "            result[key] = value\n",
    "\n",
    "    if not result:\n",
    "        return \"No information available for this timerange\"\n",
    "\n",
    "    return result\n",
    "\n",
    "get_messages_tool = FunctionTool.from_defaults(\n",
    "    fn=get_messages,\n",
    "    name=\"get_messages\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ee7b71-0c6d-40f0-9a5a-73a98d3619ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    find_person_tool,\n",
    "    find_orgnization_tool,\n",
    "    get_messages_tool,\n",
    "    knowledge_tool,\n",
    "]\n",
    "\n",
    "#memory = ChatMemoryBuffer(token_limit=2000)\n",
    "\n",
    "\n",
    "# extract only entities\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "class Organization(BaseModel):\n",
    "    \"\"\"Organization entity\"\"\"\n",
    "    name: str\n",
    "\n",
    "ollama_model = OpenAIModel(model_name=LLM_MODEL, base_url=f\"{OLLAMA_URL}/v1\")\n",
    "#ollama_model = OpenAIModel(model_name='ollama:llama3.2', base_url=OLLAMA_URL)\n",
    "agent = Agent(ollama_model, result_type=Organization,system_prompt=EXTRACT_TEMPLATE_STR)\n",
    "#TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be71922-bd13-4cfe-96ae-f1864623edf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedModelBehavior",
     "evalue": "Exceeded maximum retries (1) for result validation",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedModelBehavior\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m nest_asyncio.apply()\n\u001b[32m      5\u001b[39m prod_data = [\u001b[33m\"\u001b[39m\u001b[33mDie Pilz Mafia ist eine Organisation.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDie Polnische Polizei überwacht die Pilz Mafia.\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m org_result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWhat organizations are mentioned \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprod_data\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(org_result.data)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(org_result.usage())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:558\u001b[39m, in \u001b[36mAgent.run_sync\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m infer_name \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:316\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    307\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    308\u001b[39m     result_type=result_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     usage=usage,\n\u001b[32m    315\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (final_result := agent_run.result) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mThe graph run did not finish properly\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/agent.py:1352\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1348\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1350\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, ResultDataT] | End[FinalResult[ResultDataT]]:\n\u001b[32m   1351\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1353\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(next_node):\n\u001b[32m   1354\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:734\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    733\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:723\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    720\u001b[39m state = \u001b[38;5;28mself\u001b[39m.state\n\u001b[32m    721\u001b[39m deps = \u001b[38;5;28mself\u001b[39m.deps\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.graph.next(node, history, state=state, deps=deps, infer_name=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_graph/graph.py:305\u001b[39m, in \u001b[36mGraph.next\u001b[39m\u001b[34m(self, node, history, state, deps, infer_name)\u001b[39m\n\u001b[32m    303\u001b[39m     start_ts = _utils.now_utc()\n\u001b[32m    304\u001b[39m     start = perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    306\u001b[39m     duration = perf_counter() - start\n\u001b[32m    308\u001b[39m history.append(\n\u001b[32m    309\u001b[39m     NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=\u001b[38;5;28mself\u001b[39m.snapshot_state)\n\u001b[32m    310\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:365\u001b[39m, in \u001b[36mCallToolsNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\n\u001b[32m    363\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: GraphRunContext[GraphAgentState, GraphAgentDeps[DepsT, NodeRunEndT]]\n\u001b[32m    364\u001b[39m ) -> Union[ModelRequestNode[DepsT, NodeRunEndT], End[result.FinalResult[NodeRunEndT]]]:  \u001b[38;5;66;03m# noqa UP007\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(ctx):\n\u001b[32m    366\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (next_node := \u001b[38;5;28mself\u001b[39m._next_node) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mthe stream should set `self._next_node` before it ends\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/contextlib.py:221\u001b[39m, in \u001b[36m_AsyncGeneratorContextManager.__aexit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    223\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:380\u001b[39m, in \u001b[36mCallToolsNode.stream\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m stream\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Run the stream to completion if it was not finished:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _event \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:417\u001b[39m, in \u001b[36mCallToolsNode._run_stream\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    413\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m exceptions.UnexpectedModelBehavior(\u001b[33m'\u001b[39m\u001b[33mReceived empty model response\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m._events_iterator = _run_stream()\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._events_iterator:\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:411\u001b[39m, in \u001b[36mCallToolsNode._run_stream.<locals>._run_stream\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m texts:\n\u001b[32m    410\u001b[39m     \u001b[38;5;66;03m# No events are emitted during the handling of text responses, so we don't need to yield anything\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_text_response(ctx, texts)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.UnexpectedModelBehavior(\u001b[33m'\u001b[39m\u001b[33mReceived empty model response\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:523\u001b[39m, in \u001b[36mCallToolsNode._handle_text_response\u001b[39m\u001b[34m(self, ctx, texts)\u001b[39m\n\u001b[32m    521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_final_result(ctx, result.FinalResult(result_data, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), [])\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_result_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ModelRequestNode[DepsT, NodeRunEndT](\n\u001b[32m    525\u001b[39m         _messages.ModelRequest(\n\u001b[32m    526\u001b[39m             parts=[\n\u001b[32m   (...)\u001b[39m\u001b[32m    531\u001b[39m         )\n\u001b[32m    532\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:72\u001b[39m, in \u001b[36mGraphAgentState.increment_retries\u001b[39m\u001b[34m(self, max_result_retries)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m.retries += \u001b[32m1\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.retries > max_result_retries:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.UnexpectedModelBehavior(\n\u001b[32m     73\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExceeded maximum retries (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_result_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) for result validation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     74\u001b[39m     )\n",
      "\u001b[31mUnexpectedModelBehavior\u001b[39m: Exceeded maximum retries (1) for result validation"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "prod_data = [\"Die Pilz Mafia ist eine Organisation.\", \"Die Polnische Polizei überwacht die Pilz Mafia.\"]\n",
    "\n",
    "org_result = agent.run_sync(f'What organizations are mentioned {prod_data}')\n",
    "print(org_result.data)\n",
    "print(org_result.usage())\n",
    "#memory.save(org_result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bd38bdc-5ca4-4ee4-aaef-c9547d44e95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start prompt\n",
      "> Running step 78b703d0-8182-4034-b40a-ab0edbc366cc. Step input: Wer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_transports/default.py:72\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_transports/default.py:236\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:126\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    125\u001b[39m exc_map: ExceptionMapping = {socket.timeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     14\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mWer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m xprompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mWer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m             Liste alle informationen und fakten die du findest in der antwort auf.\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m            questions context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion_context\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[33m            8. Kontrolliere ob alle Punkte dieser liste erfüllt sind\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m          \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#response = llm.complete(prompt)\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m#memory.save_context({\"input\": prompt}, {\"output\": str(response)})\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     51\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m dispatcher.event(\n\u001b[32m     54\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     55\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/callbacks/utils.py:41\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m callback_manager = cast(CallbackManager, callback_manager)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager.as_trace(trace_id):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/base/agent/types.py:44\u001b[39m, in \u001b[36mBaseAgent._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) -> RESPONSE_TYPE:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     agent_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m     49\u001b[39m         response=\u001b[38;5;28mstr\u001b[39m(agent_response), source_nodes=agent_response.source_nodes\n\u001b[32m     50\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/callbacks/utils.py:41\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m callback_manager = cast(CallbackManager, callback_manager)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager.as_trace(trace_id):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/agent/runner/base.py:646\u001b[39m, in \u001b[36mAgentRunner.chat\u001b[39m\u001b[34m(self, message, chat_history, tool_choice)\u001b[39m\n\u001b[32m    641\u001b[39m     tool_choice = \u001b[38;5;28mself\u001b[39m.default_tool_choice\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    643\u001b[39m     CBEventType.AGENT_STEP,\n\u001b[32m    644\u001b[39m     payload={EventPayload.MESSAGES: [message]},\n\u001b[32m    645\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     chat_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatResponseMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWAIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[32m    653\u001b[39m     e.on_end(payload={EventPayload.RESPONSE: chat_response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/agent/runner/base.py:578\u001b[39m, in \u001b[36mAgentRunner._chat\u001b[39m\u001b[34m(self, message, chat_history, tool_choice, mode)\u001b[39m\n\u001b[32m    575\u001b[39m dispatcher.event(AgentChatWithStepStartEvent(user_msg=message))\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    577\u001b[39m     \u001b[38;5;66;03m# pass step queue in as argument, assume step executor is stateless\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m     cur_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    582\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cur_step_output.is_last:\n\u001b[32m    583\u001b[39m         result_output = cur_step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/agent/runner/base.py:412\u001b[39m, in \u001b[36mAgentRunner._run_step\u001b[39m\u001b[34m(self, task_id, step, input, mode, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# TODO: figure out if you can dynamically swap in different step executors\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# not clear when you would do that by theoretically possible\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == ChatResponseMode.WAIT:\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m     cur_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == ChatResponseMode.STREAM:\n\u001b[32m    414\u001b[39m     cur_step_output = \u001b[38;5;28mself\u001b[39m.agent_worker.stream_step(step, task, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/callbacks/utils.py:41\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m callback_manager = cast(CallbackManager, callback_manager)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager.as_trace(trace_id):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/agent/react/step.py:781\u001b[39m, in \u001b[36mReActAgentWorker.run_step\u001b[39m\u001b[34m(self, step, task, **kwargs)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrun_step\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, step: TaskStep, task: Task, **kwargs: Any) -> TaskStepOutput:\n\u001b[32m    780\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run step.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/agent/react/step.py:567\u001b[39m, in \u001b[36mReActAgentWorker._run_step\u001b[39m\u001b[34m(self, step, task)\u001b[39m\n\u001b[32m    559\u001b[39m input_chat = \u001b[38;5;28mself\u001b[39m._react_chat_formatter.format(\n\u001b[32m    560\u001b[39m     tools,\n\u001b[32m    561\u001b[39m     chat_history=task.memory.get(\u001b[38;5;28minput\u001b[39m=task.input)\n\u001b[32m    562\u001b[39m     + task.extra_state[\u001b[33m\"\u001b[39m\u001b[33mnew_memory\u001b[39m\u001b[33m\"\u001b[39m].get_all(),\n\u001b[32m    563\u001b[39m     current_reasoning=task.extra_state[\u001b[33m\"\u001b[39m\u001b[33mcurrent_reasoning\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    564\u001b[39m )\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# send prompt\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m chat_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_chat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# given react prompt outputs, call tools or return response\u001b[39;00m\n\u001b[32m    569\u001b[39m reasoning_steps, is_done = \u001b[38;5;28mself\u001b[39m._process_actions(\n\u001b[32m    570\u001b[39m     task, tools, output=chat_response\n\u001b[32m    571\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/core/llms/callbacks.py:172\u001b[39m, in \u001b[36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[39m\u001b[34m(_self, messages, **kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    164\u001b[39m     CBEventType.LLM,\n\u001b[32m    165\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     },\n\u001b[32m    170\u001b[39m )\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     f_return_val = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    174\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    175\u001b[39m         CBEventType.LLM,\n\u001b[32m    176\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    177\u001b[39m         event_id=event_id,\n\u001b[32m    178\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/llama_index/llms/ollama/base.py:261\u001b[39m, in \u001b[36mOllama.chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m ollama_messages = \u001b[38;5;28mself\u001b[39m._convert_to_ollama_messages(messages)\n\u001b[32m    259\u001b[39m tools = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mollama_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjson_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m tool_calls = response[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ChatResponse(\n\u001b[32m    273\u001b[39m     message=ChatMessage(\n\u001b[32m    274\u001b[39m         content=response[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    278\u001b[39m     raw=response,\n\u001b[32m    279\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/ollama/_client.py:236\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    233\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m images := message.get(\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    234\u001b[39m     message[\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m] = [_encode_image(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mformat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moptions\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkeep_alive\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/ollama/_client.py:99\u001b[39m, in \u001b[36mClient._request_stream\u001b[39m\u001b[34m(self, stream, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_stream\u001b[39m(\n\u001b[32m     94\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     95\u001b[39m   *args,\n\u001b[32m     96\u001b[39m   stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     97\u001b[39m   **kwargs,\n\u001b[32m     98\u001b[39m ) -> Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream(*args, **kwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/ollama/_client.py:70\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, method, url, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, **kwargs) -> httpx.Response:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     73\u001b[39m     response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_client.py:837\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    822\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[32m    824\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    825\u001b[39m     method=method,\n\u001b[32m    826\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    835\u001b[39m     extensions=extensions,\n\u001b[32m    836\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_client.py:926\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    924\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_client.py:954\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    951\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    960\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_client.py:991\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    989\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_client.py:1027\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m     )\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1031\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_transports/default.py:235\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request.stream, SyncByteStream)\n\u001b[32m    223\u001b[39m req = httpcore.Request(\n\u001b[32m    224\u001b[39m     method=request.method,\n\u001b[32m    225\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     extensions=request.extensions,\n\u001b[32m    234\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    236\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    160\u001b[39m     value = typ()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/httpx/_transports/default.py:89\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     88\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: timed out"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.memory import ChatMemoryBuffer, ChatSummaryMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer(token_limit=2000)\n",
    "agent = ReActAgent.from_tools(tools, llm=llm, verbose=True, context=context, tool_choice='auto',max_iterations=25, timeout=3000, memory=memory) #, chat_history=memory)\n",
    "\n",
    "# update agent system prompt\n",
    "react_system_prompt = PromptTemplate(react_system_header_str)\n",
    "agent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})\n",
    "agent.reset()\n",
    "print(\"start prompt\")\n",
    "#prompt = \"Who is Anna Gölding and what other person may be related to her? to which organzations may she be related?\"\n",
    "question_context = \"\"\"context: c1, zeitbereich: 2025-02-01T00:00:00+00:00 to 2025-02-15T00:00:00+00:00\"\"\"\n",
    "prompt = f\"\"\"Wer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\"\"\"\n",
    "xprompt = f\"\"\"Wer war Anna Gölding und welche andren personen oder organisationen stehen mit ihr in verbindung?\n",
    "             Liste alle informationen und fakten die du findest in der antwort auf.\n",
    "            questions context: {question_context}\n",
    "            1. Analysiere die Person bekannt ist im find person tool.\n",
    "            2. Analysiere die Person verbindungen zu anderen Personen oder Organisationen hat\n",
    "            3. Prüfe ob Nachriten (messages) im context dieser Personen im gesuchten Zeitbereich statgefunden haben mit dem get_messages tool.\n",
    "            4. Nenne die Anzahl der conversationen\n",
    "            5. Nenne die Teilnehmer der conversationen\n",
    "            6. Fasse den Inhalt der Kommunikation zusammen\n",
    "            7. Prüfe ob Entitäten wie Personen, Organisationen oder Orte in der Nachrichten vorkommen, die bisher nicht bekannt sind.\n",
    "            8. Kontrolliere ob alle Punkte dieser liste erfüllt sind\n",
    "          \"\"\"\n",
    "response = agent.query(prompt)\n",
    "#response = llm.complete(prompt)\n",
    "\n",
    "#memory.save_context({\"input\": prompt}, {\"output\": str(response)})\n",
    "\n",
    "print(f\"AI: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
